{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import voc12.data\n",
    "import scipy.misc\n",
    "import importlib\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from tool import imutils, pyutils, visualization\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1a): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (b2): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv_branch1): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  )\n",
       "  (b2_1): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b2_2): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b3): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv_branch1): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  )\n",
       "  (b3_1): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b3_2): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b4): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (conv_branch1): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "  )\n",
       "  (b4_1): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b4_2): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b4_3): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b4_4): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b4_5): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (b5): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    (conv_branch1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (b5_1): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (b5_2): ResBlock(\n",
       "    (bn_branch2a): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2b1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "  )\n",
       "  (b6): ResBlock_bot(\n",
       "    (bn_branch2a): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_2b1): Dropout2d(p=0.3, inplace=False)\n",
       "    (conv_branch2b1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    (bn_branch2b2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_2b2): Dropout2d(p=0.3, inplace=False)\n",
       "    (conv_branch2b2): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv_branch1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (b7): ResBlock_bot(\n",
       "    (bn_branch2a): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv_branch2a): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn_branch2b1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_2b1): Dropout2d(p=0.5, inplace=False)\n",
       "    (conv_branch2b1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "    (bn_branch2b2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout_2b2): Dropout2d(p=0.5, inplace=False)\n",
       "    (conv_branch2b2): Conv2d(2048, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (conv_branch1): Conv2d(2048, 4096, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (bn7): BatchNorm2d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout7): Dropout2d(p=0.5, inplace=False)\n",
       "  (fc8): Conv2d(4096, 21, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (f8_3): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (f8_4): Conv2d(1024, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (f9): Conv2d(195, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = getattr(importlib.import_module(\"network.resnet38_SEAM\"), 'Net')()\n",
    "model.load_state_dict(torch.load(\"resnet38_SEAM.pth\"))\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_dataset = voc12.data.VOC12ClsDatasetMSF(\"voc12/bb_list.txt\", voc12_root=\"/home/bnair/data/chest14\",\n",
    "                                                  scales=[0.5, 1.0, 1.5, 2.0],\n",
    "                                                  inter_transform=torchvision.transforms.Compose(\n",
    "                                                       [np.asarray,\n",
    "                                                        model.normalize,\n",
    "                                                        imutils.HWC_to_CHW]))\n",
    "\n",
    "infer_data_loader = DataLoader(infer_dataset, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = torch.cuda.device_count()\n",
    "model_replicas = torch.nn.parallel.replicate(model, list(range(n_gpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor*255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor)>3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return PIL.Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchcam.utils import overlay_mask\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# get list of images in outcam/ folder\n",
    "outcam_img_list = os.listdir(\"outcam/\")\n",
    "# print(outcam_img_list)\n",
    "\n",
    "for iter, (img_name, img_list, label) in enumerate(infer_data_loader):\n",
    "    img_name = img_name[0]; label = label[0]\n",
    "\n",
    "    if img_name + '.png' not in outcam_img_list:\n",
    "        print(\"{} not in outcam/\".format(img_name))\n",
    "        img_path = voc12.data.get_img_path(img_name, \"/home/bnair/data/chest14\")\n",
    "        orig_img = np.asarray(Image.open(img_path))\n",
    "        orig_img_size = orig_img.shape[:2]\n",
    "        def _work(i, img):\n",
    "                with torch.no_grad():\n",
    "                    with torch.cuda.device(i%n_gpus):\n",
    "                        pred= model_replicas[i%n_gpus](img.cuda())\n",
    "                        img = tensor_to_image(pred[0][0][0].cpu())\n",
    "                        im1 = img.save(os.path.join('/home/bnair/SEAM/outcam', img_name + '.png'))\n",
    "                        return im1\n",
    "\n",
    "        thread_pool = pyutils.BatchThreader(_work, list(enumerate(img_list)),\n",
    "                                                batch_size=2, prefetch_size=0, processes=1)\n",
    "        \n",
    "        cam_list = thread_pool.pop_results()\n",
    "\n",
    "    # else:\n",
    "        # print(\"Already processed: \" + img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[2], boxB[2])\n",
    "\tyB = min(boxA[3], boxB[3])\n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "\tboxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the interesection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "\t# return the intersection over union value\n",
    "\treturn iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "984it [00:00, 1144.83it/s]\n"
     ]
    }
   ],
   "source": [
    "from chitra.image import Chitra\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "bboxes = pd.read_csv('./voc12/BBox_List_2017.csv')\n",
    "localization_images = {}\n",
    "for index, row in tqdm(bboxes.iterrows()):\n",
    "    img_name = row['Image Index']\n",
    "    if img_name[1:] in os.listdir('/home/bnair/SEAM/outcam'):\n",
    "        box = [[row['x'], row['y'], row['h'], row['w']]]\n",
    "        label = [row['Finding Label']]\n",
    "        image = Chitra('/home/bnair/data/chest14/'+img_name, labels=label, bboxes=box, box_format='xyhw')\n",
    "        # image.resize_image_with_bbox((224, 224))\n",
    "        # localization_images[img_name] = {\n",
    "        #     'label': row['Finding Label'],\n",
    "        #     'xA': (image.bboxes[0].x1/1024)*512,\n",
    "        #     'yA': (image.bboxes[0].y1/1024)*512,\n",
    "        #     'xB': (image.bboxes[0].x2/1024)*512,\n",
    "        #     'yB': (image.bboxes[0].y2/1024)*512,\n",
    "        # }\n",
    "        localization_images[img_name] = {\n",
    "            'label': row['Finding Label'],\n",
    "            'xA': (image.bboxes[0].x1),\n",
    "            'yA': (image.bboxes[0].y1),\n",
    "            'xB': (image.bboxes[0].x2),\n",
    "            'yB': (image.bboxes[0].y2),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_from_image(image_file):\n",
    "    bboxes = pd.read_csv('./BBox_List_2017.csv')\n",
    "    img_row = bboxes[bboxes['Image Index'] == image_file]\n",
    "    return img_row['Finding Label'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "diseases_available = bboxes['Finding Label'].unique()\n",
    "for disease in diseases_available:\n",
    "    scores[disease] = {\n",
    "        'count': bboxes[bboxes['Finding Label'] == disease].shape[0],\n",
    "        'evaluated': 0,\n",
    "        'total_iou': 0,\n",
    "        'total_cdice': 0,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0008554_009.png\n",
      "0020774_000.png\n"
     ]
    }
   ],
   "source": [
    "for img_name in os.listdir('/home/bnair/SEAM/outcam'):\n",
    "    # print(img_name)\n",
    "    try:\n",
    "        img = cv2.imread(os.path.join('/home/bnair/SEAM/outcam', img_name))\n",
    "        img = cv2.resize(img, (1024, 1024))\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        thresh = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "        cv2.imwrite(\"thresh.png\", thresh)\n",
    "        contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "        bboxes = []\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if x == 0 or x == 1024 - 1 or y == 0 or y == 1024 - 1:\n",
    "                continue\n",
    "            bboxes.append((x,y,w,h))\n",
    "            # bboxes.append([x, y, x+w, y+h])\n",
    "        if len(bboxes) == 0:\n",
    "            scores[localization_images[\"0\"+img_name]['label']]['evaluated'] += 1\n",
    "            continue\n",
    "        ious = []\n",
    "        iou_bb = {}\n",
    "        gt_XA, gt_YA, gt_XB, gt_YB = 0, 0, 0, 0\n",
    "        xA, yA, xB, yB = 0, 0, 0, 0\n",
    "        for bbox in bboxes:\n",
    "            xA, yA, xB, yB = bbox\n",
    "            label = localization_images[\"0\"+img_name]['label']\n",
    "            gt_XA = localization_images[\"0\"+img_name]['xA']\n",
    "            gt_YA = localization_images[\"0\"+img_name]['yA']\n",
    "            gt_XB = localization_images[\"0\"+img_name]['xB']\n",
    "            gt_YB = localization_images[\"0\"+img_name]['yB']\n",
    "            # draw both the boundiug boxes and the label on the image\n",
    "            ious.append(bb_intersection_over_union([int(xA), int(yA), int(xB), int(yB)], [int(gt_XA), int(gt_YA), int(gt_XB), int(gt_YB)]))\n",
    "            iou_bb[bb_intersection_over_union([int(xA), int(yA), int(xB), int(yB)], [int(gt_XA), int(gt_YA), int(gt_XB), int(gt_YB)])] = bbox\n",
    "        # print(max(ious))\n",
    "        scores[label]['total_iou'] += max(ious)\n",
    "        # scores[label]['bbox'] = iou_bb[max(ious)] \n",
    "        scores[label]['evaluated'] += 1\n",
    "        xA, yA, xB, yB = iou_bb[max(ious)]\n",
    "        img = cv2.imread(os.path.join('/home/bnair/data/chest14', \"0\" + img_name))\n",
    "        # img = cv2.resize(img, (512, 512))\n",
    "        cv2.rectangle(img, (int(xA), int(yA)), (int(xB), int(yB)), (0, 0, 255), 2)\n",
    "        cv2.rectangle(img, (int(gt_XA), int(gt_YA)), (int(gt_XB), int(gt_YB)), (0, 255, 0), 2)\n",
    "        cv2.imwrite(os.path.join('/home/bnair/SEAM/outcamgtbb', label + '_' + img_name), img)\n",
    "    except:\n",
    "        print(img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atelectasis': {'count': 180,\n",
       "  'evaluated': 157,\n",
       "  'total_iou': 0.0,\n",
       "  'total_cdice': 0},\n",
       " 'Cardiomegaly': {'count': 146,\n",
       "  'evaluated': 135,\n",
       "  'total_iou': 0.0,\n",
       "  'total_cdice': 0},\n",
       " 'Effusion': {'count': 153,\n",
       "  'evaluated': 114,\n",
       "  'total_iou': 0.0,\n",
       "  'total_cdice': 0},\n",
       " 'Infiltrate': {'count': 123,\n",
       "  'evaluated': 101,\n",
       "  'total_iou': 0.0,\n",
       "  'total_cdice': 0},\n",
       " 'Mass': {'count': 85, 'evaluated': 78, 'total_iou': 0.0, 'total_cdice': 0},\n",
       " 'Nodule': {'count': 79, 'evaluated': 74, 'total_iou': 0.0, 'total_cdice': 0},\n",
       " 'Pneumonia': {'count': 120,\n",
       "  'evaluated': 118,\n",
       "  'total_iou': 0.0,\n",
       "  'total_cdice': 0},\n",
       " 'Pneumothorax': {'count': 98,\n",
       "  'evaluated': 98,\n",
       "  'total_iou': 0.0,\n",
       "  'total_cdice': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
